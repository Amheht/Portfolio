# Amheht's Portfolio

Welcome!  

Thank you for taking the time to view my portfolio. If you have any questions, please feel free to reach out to me!


## About

- This portfolio showcases my work in Artificial Intelligence, Machine Learning, and Software Engineering.
- Each project included here demonstrates real-world technical skills, hands-on model development, and applied research.
- All codebases are original unless otherwise noted.



## Projects

### 1. [LLMini â€” Miniature GPT-Style Language Model](./Portfolio/LLMini)

**Summary:**
A lightweight Transformer-based language model (similar to GPT) built from scratch using TensorFlow and Huggingface Tokenizers.
Trained on a curated corpus of classic literature from Project Gutenberg.

**Key Features:**
- Custom Byte Pair Encoding (BPE) tokenizer
- Decoder-only Transformer architecture
- Token-level next-word prediction training
- Text generation based on prompt continuation
- Modular design for scalability

**Technologies:**  
TensorFlow, Python, Huggingface Tokenizers

**Links:**
- [Project Repository](./LLMini)
- [Open in Google Colab](https://colab.research.google.com/github/Amheht/Portfolio/blob/main/LLMini/colab_notebook.ipynb)



## Contact

- GitHub: [Amheht](https://github.com/Amheht)



## License

All projects and files contained within this portfolio are licensed under the [MIT License](./LICENSE).

> **Disclaimer:**  
> All projects contained within this portfolio are provided "as is," without warranty of any kind, express or implied.
> Use of this code at your own risk.

